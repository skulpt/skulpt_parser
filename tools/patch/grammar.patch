diff --git a/Grammar/python.gram b/Grammar/python.gram
index 64e205e7fd..34c9a0b6b5 100644
--- a/Grammar/python.gram
+++ b/Grammar/python.gram
@@ -2,7 +2,7 @@
 
 @trailer '''
 void *
-_PyPegen_parse(Parser *p)
+pegen.parse(Parser *p)
 {
     // Initialize keywords
     p->keywords = reserved_keywords;
@@ -27,51 +27,51 @@ _PyPegen_parse(Parser *p)
 
 // The end
 '''
-file[mod_ty]: a=[statements] ENDMARKER { _PyPegen_make_module(p, a) }
-interactive[mod_ty]: a=statement_newline { Interactive(a, p->arena) }
-eval[mod_ty]: a=expressions NEWLINE* ENDMARKER { Expression(a, p->arena) }
-func_type[mod_ty]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* ENDMARKER { FunctionType(a, b, p->arena) }
-fstring[expr_ty]: star_expressions
+file[mod]: a=[statements] ENDMARKER { pegen.make_module(this, a) }
+interactive[mod]: a=statement_newline { new astnodes.Interactive(a) }
+eval[mod]: a=expressions NEWLINE* ENDMARKER { new astnodes.Expression(a) }
+func_type[mod]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* ENDMARKER { new astnodes.FunctionType(a, b) }
+fstring[expr]: star_expressions
 
 # type_expressions allow */** but ignore them
 type_expressions[asdl_seq*]:
     | a=','.expression+ ',' '*' b=expression ',' '**' c=expression {
-        _PyPegen_seq_append_to_end(p, CHECK(_PyPegen_seq_append_to_end(p, a, b)), c) }
-    | a=','.expression+ ',' '*' b=expression { _PyPegen_seq_append_to_end(p, a, b) }
-    | a=','.expression+ ',' '**' b=expression { _PyPegen_seq_append_to_end(p, a, b) }
+        pegen.seq_append_to_end(this, CHECK(pegen.seq_append_to_end(this, a, b)), c) }
+    | a=','.expression+ ',' '*' b=expression { pegen.seq_append_to_end(this, a, b) }
+    | a=','.expression+ ',' '**' b=expression { pegen.seq_append_to_end(this, a, b) }
     | '*' a=expression ',' '**' b=expression {
-        _PyPegen_seq_append_to_end(p, CHECK(_PyPegen_singleton_seq(p, a)), b) }
-    | '*' a=expression { _PyPegen_singleton_seq(p, a) }
-    | '**' a=expression { _PyPegen_singleton_seq(p, a) }
+        pegen.seq_append_to_end(this, CHECK(pegen.singleton_seq(this, a)), b) }
+    | '*' a=expression { pegen.singleton_seq(this, a) }
+    | '**' a=expression { pegen.singleton_seq(this, a) }
     | ','.expression+
 
-statements[asdl_seq*]: a=statement+ { _PyPegen_seq_flatten(p, a) }
-statement[asdl_seq*]: a=compound_stmt { _PyPegen_singleton_seq(p, a) } | simple_stmt
+statements[asdl_seq*]: a=statement+ { pegen.seq_flatten(this, a) }
+statement[asdl_seq*]: a=compound_stmt { pegen.singleton_seq(this, a) } | simple_stmt
 statement_newline[asdl_seq*]:
-    | a=compound_stmt NEWLINE { _PyPegen_singleton_seq(p, a) }
+    | a=compound_stmt NEWLINE { pegen.singleton_seq(this, a) }
     | simple_stmt
-    | NEWLINE { _PyPegen_singleton_seq(p, CHECK(_Py_Pass(EXTRA))) }
-    | ENDMARKER { _PyPegen_interactive_exit(p) }
+    | NEWLINE { pegen.singleton_seq(this, CHECK(new astnodes.Pass(...EXTRA))) }
+    | ENDMARKER { pegen.interactive_exit(p) }
 simple_stmt[asdl_seq*]:
-    | a=small_stmt !';' NEWLINE { _PyPegen_singleton_seq(p, a) } # Not needed, there for speedup
+    | a=small_stmt !';' NEWLINE { pegen.singleton_seq(this, a) } # Not needed, there for speedup
     | a=';'.small_stmt+ [';'] NEWLINE { a }
 # NOTE: assignment MUST precede expression, else parsing a simple assignment
 # will throw a SyntaxError.
-small_stmt[stmt_ty] (memo):
+small_stmt[stmt] (memo):
     | assignment
-    | e=star_expressions { _Py_Expr(e, EXTRA) }
+    | e=star_expressions { new astnodes.Expr(e, ...EXTRA) }
     | &'return' return_stmt
     | &('import' | 'from') import_stmt
     | &'raise' raise_stmt
-    | 'pass' { _Py_Pass(EXTRA) }
+    | 'pass' { new astnodes.Pass(...EXTRA) }
     | &'del' del_stmt
     | &'yield' yield_stmt
     | &'assert' assert_stmt
-    | 'break' { _Py_Break(EXTRA) }
-    | 'continue' { _Py_Continue(EXTRA) }
+    | 'break' { new astnodes.Break(...EXTRA) }
+    | 'continue' { new astnodes.Continue(...EXTRA) }
     | &'global' global_stmt
     | &'nonlocal' nonlocal_stmt
-compound_stmt[stmt_ty]:
+compound_stmt[stmt]:
     | &('def' | '@' | ASYNC) function_def
     | &'if' if_stmt
     | &('class' | '@') class_def
@@ -81,162 +81,160 @@ compound_stmt[stmt_ty]:
     | &'while' while_stmt
 
 # NOTE: annotated_rhs may start with 'yield'; yield_expr must start with 'yield'
-assignment[stmt_ty]:
+assignment[stmt]:
     | a=NAME ':' b=expression c=['=' d=annotated_rhs { d }] {
         CHECK_VERSION(
             6,
             "Variable annotation syntax is",
-            _Py_AnnAssign(CHECK(_PyPegen_set_expr_context(p, a, Store)), b, c, 1, EXTRA)
+            new astnodes.AnnAssign(CHECK(pegen.set_expr_context(this, a, new astnodes.Store())), b, c, 1, ...EXTRA)
         ) }
     | a=('(' b=single_target ')' { b }
          | single_subscript_attribute_target) ':' b=expression c=['=' d=annotated_rhs { d }] {
-        CHECK_VERSION(6, "Variable annotations syntax is", _Py_AnnAssign(a, b, c, 0, EXTRA)) }
+        CHECK_VERSION(6, "Variable annotations syntax is", new astnodes.AnnAssign(a, b, c, 0, ...EXTRA)) }
     | a=(z=star_targets '=' { z })+ b=(yield_expr | star_expressions) !'=' tc=[TYPE_COMMENT] {
-         _Py_Assign(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }
+         new astnodes.Assign(a, b, NEW_TYPE_COMMENT(this, tc), ...EXTRA) }
     | a=single_target b=augassign ~ c=(yield_expr | star_expressions) {
-         _Py_AugAssign(a, b->kind, c, EXTRA) }
+         new astnodes.AugAssign(a, b.kind, c, ...EXTRA) }
     | invalid_assignment
 
 augassign[AugOperator*]:
-    | '+=' { _PyPegen_augoperator(p, Add) }
-    | '-=' { _PyPegen_augoperator(p, Sub) }
-    | '*=' { _PyPegen_augoperator(p, Mult) }
-    | '@=' { CHECK_VERSION(5, "The '@' operator is", _PyPegen_augoperator(p, MatMult)) }
-    | '/=' { _PyPegen_augoperator(p, Div) }
-    | '%=' { _PyPegen_augoperator(p, Mod) }
-    | '&=' { _PyPegen_augoperator(p, BitAnd) }
-    | '|=' { _PyPegen_augoperator(p, BitOr) }
-    | '^=' { _PyPegen_augoperator(p, BitXor) }
-    | '<<=' { _PyPegen_augoperator(p, LShift) }
-    | '>>=' { _PyPegen_augoperator(p, RShift) }
-    | '**=' { _PyPegen_augoperator(p, Pow) }
-    | '//=' { _PyPegen_augoperator(p, FloorDiv) }
-
-global_stmt[stmt_ty]: 'global' a=','.NAME+ {
-    _Py_Global(CHECK(_PyPegen_map_names_to_ids(p, a)), EXTRA) }
-nonlocal_stmt[stmt_ty]: 'nonlocal' a=','.NAME+ {
-    _Py_Nonlocal(CHECK(_PyPegen_map_names_to_ids(p, a)), EXTRA) }
-
-yield_stmt[stmt_ty]: y=yield_expr { _Py_Expr(y, EXTRA) }
-
-assert_stmt[stmt_ty]: 'assert' a=expression b=[',' z=expression { z }] { _Py_Assert(a, b, EXTRA) }
-
-del_stmt[stmt_ty]:
-    | 'del' a=del_targets &(';' | NEWLINE) { _Py_Delete(a, EXTRA) }
+    | '+=' { pegen.augoperator(this, new astnodes.Add()) }
+    | '-=' { pegen.augoperator(this, new astnodes.Sub()) }
+    | '*=' { pegen.augoperator(this, new astnodes.Mult()) }
+    | '@=' { CHECK_VERSION(5, "The '@' operator is", pegen.augoperator(this, new astnodes.MatMult())) }
+    | '/=' { pegen.augoperator(this, new astnodes.Div()) }
+    | '%=' { pegen.augoperator(this, new astnodes.Mod()) }
+    | '&=' { pegen.augoperator(this, new astnodes.BitAnd()) }
+    | '|=' { pegen.augoperator(this, new astnodes.BitOr()) }
+    | '^=' { pegen.augoperator(this, new astnodes.BitXor()) }
+    | '<<=' { pegen.augoperator(this, new astnodes.LShift()) }
+    | '>>=' { pegen.augoperator(this, new astnodes.RShift()) }
+    | '**=' { pegen.augoperator(this, new astnodes.Pow()) }
+    | '//=' { pegen.augoperator(this, new astnodes.FloorDiv()) }
+
+global_stmt[stmt]: 'global' a=','.NAME+ {
+    new astnodes.Global(CHECK(pegen.map_names_to_ids(this, a)), ...EXTRA) }
+nonlocal_stmt[stmt]: 'nonlocal' a=','.NAME+ {
+    new astnodes.Nonlocal(CHECK(pegen.map_names_to_ids(this, a)), ...EXTRA) }
+
+yield_stmt[stmt]: y=yield_expr { new astnodes.Expr(y, ...EXTRA) }
+
+assert_stmt[stmt]: 'assert' a=expression b=[',' z=expression { z }] { new astnodes.Assert(a, b, ...EXTRA) }
+
+del_stmt[stmt]:
+    | 'del' a=del_targets &(';' | NEWLINE) { new astnodes.Delete(a, ...EXTRA) }
     | invalid_del_stmt
 
-import_stmt[stmt_ty]: import_name | import_from
-import_name[stmt_ty]: 'import' a=dotted_as_names { _Py_Import(a, EXTRA) }
+import_stmt[stmt]: import_name | import_from
+import_name[stmt]: 'import' a=dotted_as_names { new astnodes.Import(a, ...EXTRA) }
 # note below: the ('.' | '...') is necessary because '...' is tokenized as ELLIPSIS
-import_from[stmt_ty]:
+import_from[stmt]:
     | 'from' a=('.' | '...')* b=dotted_name 'import' c=import_from_targets {
-        _Py_ImportFrom(b->v.Name.id, c, _PyPegen_seq_count_dots(a), EXTRA) }
+        new astnodes.ImportFrom(b.id, c, pegen.seq_count_dots(a), ...EXTRA) }
     | 'from' a=('.' | '...')+ 'import' b=import_from_targets {
-        _Py_ImportFrom(NULL, b, _PyPegen_seq_count_dots(a), EXTRA) }
+        new astnodes.ImportFrom(null, b, pegen.seq_count_dots(a), ...EXTRA) }
 import_from_targets[asdl_seq*]:
     | '(' a=import_from_as_names [','] ')' { a }
     | import_from_as_names !','
-    | '*' { _PyPegen_singleton_seq(p, CHECK(_PyPegen_alias_for_star(p))) }
+    | '*' { pegen.singleton_seq(this, CHECK(pegen.alias_for_star(p))) }
     | invalid_import_from_targets
 import_from_as_names[asdl_seq*]:
     | a=','.import_from_as_name+ { a }
-import_from_as_name[alias_ty]:
-    | a=NAME b=['as' z=NAME { z }] { _Py_alias(a->v.Name.id,
-                                               (b) ? ((expr_ty) b)->v.Name.id : NULL,
-                                               p->arena) }
+import_from_as_name[alias]:
+    | a=NAME b=['as' z=NAME { z }] { new astnodes.alias(a.id,
+                                               b ? b.id : null) }
 dotted_as_names[asdl_seq*]:
     | a=','.dotted_as_name+ { a }
-dotted_as_name[alias_ty]:
-    | a=dotted_name b=['as' z=NAME { z }] { _Py_alias(a->v.Name.id,
-                                                      (b) ? ((expr_ty) b)->v.Name.id : NULL,
-                                                      p->arena) }
-dotted_name[expr_ty]:
-    | a=dotted_name '.' b=NAME { _PyPegen_join_names_with_dot(p, a, b) }
+dotted_as_name[alias]:
+    | a=dotted_name b=['as' z=NAME { z }] { new astnodes.alias(a.id,
+                                                      b ? b.id : null) }
+dotted_name[expr]:
+    | a=dotted_name '.' b=NAME { pegen.join_names_with_dot(this, a, b) }
     | NAME
 
-if_stmt[stmt_ty]:
-    | 'if' a=named_expression ':' b=block c=elif_stmt { _Py_If(a, b, CHECK(_PyPegen_singleton_seq(p, c)), EXTRA) }
-    | 'if' a=named_expression ':' b=block c=[else_block] { _Py_If(a, b, c, EXTRA) }
-elif_stmt[stmt_ty]:
-    | 'elif' a=named_expression ':' b=block c=elif_stmt { _Py_If(a, b, CHECK(_PyPegen_singleton_seq(p, c)), EXTRA) }
-    | 'elif' a=named_expression ':' b=block c=[else_block] { _Py_If(a, b, c, EXTRA) }
+if_stmt[stmt]:
+    | 'if' a=named_expression ':' b=block c=elif_stmt { new astnodes.If(a, b, CHECK(pegen.singleton_seq(this, c)), ...EXTRA) }
+    | 'if' a=named_expression ':' b=block c=[else_block] { new astnodes.If(a, b, c, ...EXTRA) }
+elif_stmt[stmt]:
+    | 'elif' a=named_expression ':' b=block c=elif_stmt { new astnodes.If(a, b, CHECK(pegen.singleton_seq(this, c)), ...EXTRA) }
+    | 'elif' a=named_expression ':' b=block c=[else_block] { new astnodes.If(a, b, c, ...EXTRA) }
 else_block[asdl_seq*]: 'else' ':' b=block { b }
 
-while_stmt[stmt_ty]:
-    | 'while' a=named_expression ':' b=block c=[else_block] { _Py_While(a, b, c, EXTRA) }
+while_stmt[stmt]:
+    | 'while' a=named_expression ':' b=block c=[else_block] { new astnodes.While(a, b, c, ...EXTRA) }
 
-for_stmt[stmt_ty]:
+for_stmt[stmt]:
     | 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] b=block el=[else_block] {
-        _Py_For(t, ex, b, el, NEW_TYPE_COMMENT(p, tc), EXTRA) }
+        new astnodes.For(t, ex, b, el, NEW_TYPE_COMMENT(this, tc), ...EXTRA) }
     | ASYNC 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] b=block el=[else_block] {
-        CHECK_VERSION(5, "Async for loops are", _Py_AsyncFor(t, ex, b, el, NEW_TYPE_COMMENT(p, tc), EXTRA)) }
+        CHECK_VERSION(5, "Async for loops are", new astnodes.AsyncFor(t, ex, b, el, NEW_TYPE_COMMENT(this, tc), ...EXTRA)) }
     | invalid_for_target
 
-with_stmt[stmt_ty]:
+with_stmt[stmt]:
     | 'with' '(' a=','.with_item+ ','? ')' ':' b=block {
-        _Py_With(a, b, NULL, EXTRA) }
+        new astnodes.With(a, b, null, ...EXTRA) }
     | 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
-        _Py_With(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }
+        new astnodes.With(a, b, NEW_TYPE_COMMENT(this, tc), ...EXTRA) }
     | ASYNC 'with' '(' a=','.with_item+ ','? ')' ':' b=block {
-       CHECK_VERSION(5, "Async with statements are", _Py_AsyncWith(a, b, NULL, EXTRA)) }
+       CHECK_VERSION(5, "Async with statements are", new astnodes.AsyncWith(a, b, null, ...EXTRA)) }
     | ASYNC 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
-       CHECK_VERSION(5, "Async with statements are", _Py_AsyncWith(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA)) }
-with_item[withitem_ty]:
-    | e=expression 'as' t=star_target &(',' | ')' | ':') { _Py_withitem(e, t, p->arena) }
+       CHECK_VERSION(5, "Async with statements are", new astnodes.AsyncWith(a, b, NEW_TYPE_COMMENT(this, tc), ...EXTRA)) }
+with_item[withitem]:
+    | e=expression 'as' t=star_target &(',' | ')' | ':') { new astnodes.withitem(e, t) }
     | invalid_with_item
-    | e=expression { _Py_withitem(e, NULL, p->arena) }
+    | e=expression { new astnodes.withitem(e, null) }
 
-try_stmt[stmt_ty]:
-    | 'try' ':' b=block f=finally_block { _Py_Try(b, NULL, NULL, f, EXTRA) }
-    | 'try' ':' b=block ex=except_block+ el=[else_block] f=[finally_block] { _Py_Try(b, ex, el, f, EXTRA) }
-except_block[excepthandler_ty]:
+try_stmt[stmt]:
+    | 'try' ':' b=block f=finally_block { new astnodes.Try(b, null, null, f, ...EXTRA) }
+    | 'try' ':' b=block ex=except_block+ el=[else_block] f=[finally_block] { new astnodes.Try(b, ex, el, f, ...EXTRA) }
+except_block[excepthandler]:
     | 'except' e=expression t=['as' z=NAME { z }] ':' b=block {
-        _Py_ExceptHandler(e, (t) ? ((expr_ty) t)->v.Name.id : NULL, b, EXTRA) }
-    | 'except' ':' b=block { _Py_ExceptHandler(NULL, NULL, b, EXTRA) }
+        new astnodes.ExceptHandler(e, t ? t.id : null, b, ...EXTRA) }
+    | 'except' ':' b=block { new astnodes.ExceptHandler(null, null, b, ...EXTRA) }
 finally_block[asdl_seq*]: 'finally' ':' a=block { a }
 
-return_stmt[stmt_ty]:
-    | 'return' a=[star_expressions] { _Py_Return(a, EXTRA) }
+return_stmt[stmt]:
+    | 'return' a=[star_expressions] { new astnodes.Return(a, ...EXTRA) }
 
-raise_stmt[stmt_ty]:
-    | 'raise' a=expression b=['from' z=expression { z }] { _Py_Raise(a, b, EXTRA) }
-    | 'raise' { _Py_Raise(NULL, NULL, EXTRA) }
+raise_stmt[stmt]:
+    | 'raise' a=expression b=['from' z=expression { z }] { new astnodes.Raise(a, b, ...EXTRA) }
+    | 'raise' { new astnodes.Raise(null, null, ...EXTRA) }
 
-function_def[stmt_ty]:
-    | d=decorators f=function_def_raw { _PyPegen_function_def_decorators(p, d, f) }
+function_def[stmt]:
+    | d=decorators f=function_def_raw { pegen.function_def_decorators(this, d, f) }
     | function_def_raw
 
-function_def_raw[stmt_ty]:
+function_def_raw[stmt]:
     | 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] ':' tc=[func_type_comment] b=block {
-        _Py_FunctionDef(n->v.Name.id,
-                        (params) ? params : CHECK(_PyPegen_empty_arguments(p)),
-                        b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA) }
+        new astnodes.FunctionDef(n.id,
+                        (params) ? params : CHECK(pegen.empty_arguments(p)),
+                        b, null, a, NEW_TYPE_COMMENT(this, tc), ...EXTRA) }
     | ASYNC 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] ':' tc=[func_type_comment] b=block {
         CHECK_VERSION(
             5,
             "Async functions are",
-            _Py_AsyncFunctionDef(n->v.Name.id,
-                            (params) ? params : CHECK(_PyPegen_empty_arguments(p)),
-                            b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA)
+            new astnodes.AsyncFunctionDef(n.id,
+                            (params) ? params : CHECK(pegen.empty_arguments(p)),
+                            b, null, a, NEW_TYPE_COMMENT(this, tc), ...EXTRA)
         ) }
 func_type_comment[Token*]:
     | NEWLINE t=TYPE_COMMENT &(NEWLINE INDENT) { t }  # Must be followed by indented block
     | invalid_double_type_comments
     | TYPE_COMMENT
 
-params[arguments_ty]:
+params[arguments_]:
     | invalid_parameters
     | parameters
 
-parameters[arguments_ty]:
+parameters[arguments_]:
     | a=slash_no_default b=param_no_default* c=param_with_default* d=[star_etc] {
-        _PyPegen_make_arguments(p, a, NULL, b, c, d) }
+        pegen.make_arguments(this, a, null, b, c, d) }
     | a=slash_with_default b=param_with_default* c=[star_etc] {
-        _PyPegen_make_arguments(p, NULL, a, NULL, b, c) }
+        pegen.make_arguments(this, null, a, null, b, c) }
     | a=param_no_default+ b=param_with_default* c=[star_etc] {
-        _PyPegen_make_arguments(p, NULL, NULL, a, b, c) }
-    | a=param_with_default+ b=[star_etc] { _PyPegen_make_arguments(p, NULL, NULL, NULL, a, b)}
-    | a=star_etc { _PyPegen_make_arguments(p, NULL, NULL, NULL, NULL, a) }
+        pegen.make_arguments(this, null, null, a, b, c) }
+    | a=param_with_default+ b=[star_etc] { pegen.make_arguments(this, null, null, null, a, b)}
+    | a=star_etc { pegen.make_arguments(this, null, null, null, null, a) }
 
 # Some duplication here because we can't write (',' | &')'),
 # which is because we don't support empty alternatives (yet).
@@ -245,18 +243,18 @@ slash_no_default[asdl_seq*]:
     | a=param_no_default+ '/' ',' { a }
     | a=param_no_default+ '/' &')' { a }
 slash_with_default[SlashWithDefault*]:
-    | a=param_no_default* b=param_with_default+ '/' ',' { _PyPegen_slash_with_default(p, a, b) }
-    | a=param_no_default* b=param_with_default+ '/' &')' { _PyPegen_slash_with_default(p, a, b) }
+    | a=param_no_default* b=param_with_default+ '/' ',' { pegen.slash_with_default(this, a, b) }
+    | a=param_no_default* b=param_with_default+ '/' &')' { pegen.slash_with_default(this, a, b) }
 
 star_etc[StarEtc*]:
     | '*' a=param_no_default b=param_maybe_default* c=[kwds] {
-        _PyPegen_star_etc(p, a, b, c) }
+        pegen.star_etc(this, a, b, c) }
     | '*' ',' b=param_maybe_default+ c=[kwds] {
-        _PyPegen_star_etc(p, NULL, b, c) }
-    | a=kwds { _PyPegen_star_etc(p, NULL, NULL, a) }
+        pegen.star_etc(this, null, b, c) }
+    | a=kwds { pegen.star_etc(this, null, null, a) }
     | invalid_star_etc
 
-kwds[arg_ty]: '**' a=param_no_default { a }
+kwds[arg]: '**' a=param_no_default { a }
 
 # One parameter.  This *includes* a following comma and type comment.
 #
@@ -270,71 +268,71 @@ kwds[arg_ty]: '**' a=param_no_default { a }
 # - No comma, optional type comment, must be followed by close paren
 # The latter form is for a final parameter without trailing comma.
 #
-param_no_default[arg_ty]:
-    | a=param ',' tc=TYPE_COMMENT? { _PyPegen_add_type_comment_to_arg(p, a, tc) }
-    | a=param tc=TYPE_COMMENT? &')' { _PyPegen_add_type_comment_to_arg(p, a, tc) }
+param_no_default[arg]:
+    | a=param ',' tc=TYPE_COMMENT? { pegen.add_type_comment_to_arg(this, a, tc) }
+    | a=param tc=TYPE_COMMENT? &')' { pegen.add_type_comment_to_arg(this, a, tc) }
 param_with_default[NameDefaultPair*]:
-    | a=param c=default ',' tc=TYPE_COMMENT? { _PyPegen_name_default_pair(p, a, c, tc) }
-    | a=param c=default tc=TYPE_COMMENT? &')' { _PyPegen_name_default_pair(p, a, c, tc) }
+    | a=param c=default ',' tc=TYPE_COMMENT? { pegen.name_default_pair(this, a, c, tc) }
+    | a=param c=default tc=TYPE_COMMENT? &')' { pegen.name_default_pair(this, a, c, tc) }
 param_maybe_default[NameDefaultPair*]:
-    | a=param c=default? ',' tc=TYPE_COMMENT? { _PyPegen_name_default_pair(p, a, c, tc) }
-    | a=param c=default? tc=TYPE_COMMENT? &')' { _PyPegen_name_default_pair(p, a, c, tc) }
-param[arg_ty]: a=NAME b=annotation? { _Py_arg(a->v.Name.id, b, NULL, EXTRA) }
+    | a=param c=default? ',' tc=TYPE_COMMENT? { pegen.name_default_pair(this, a, c, tc) }
+    | a=param c=default? tc=TYPE_COMMENT? &')' { pegen.name_default_pair(this, a, c, tc) }
+param[arg]: a=NAME b=annotation? { new astnodes.arg(a.id, b, null, ...EXTRA) }
 
-annotation[expr_ty]: ':' a=expression { a }
-default[expr_ty]: '=' a=expression { a }
+annotation[expr]: ':' a=expression { a }
+default[expr]: '=' a=expression { a }
 
 decorators[asdl_seq*]: a=('@' f=named_expression NEWLINE { f })+ { a }
 
-class_def[stmt_ty]:
-    | a=decorators b=class_def_raw { _PyPegen_class_def_decorators(p, a, b) }
+class_def[stmt]:
+    | a=decorators b=class_def_raw { pegen.class_def_decorators(this, a, b) }
     | class_def_raw
-class_def_raw[stmt_ty]:
-    | 'class' a=NAME b=['(' z=[arguments] ')' { z }] ':' c=block {
-        _Py_ClassDef(a->v.Name.id,
-                     (b) ? ((expr_ty) b)->v.Call.args : NULL,
-                     (b) ? ((expr_ty) b)->v.Call.keywords : NULL,
-                     c, NULL, EXTRA) }
+class_def_raw[stmt]:
+    | 'class' a=NAME b=['(' z=[arguments_] ')' { z }] ':' c=block {
+        new astnodes.ClassDef(a.id,
+                     b ? b.args : null,
+                     b ? b.keywords : null,
+                     c, null, ...EXTRA) }
 
 block[asdl_seq*] (memo):
     | NEWLINE INDENT a=statements DEDENT { a }
     | simple_stmt
     | invalid_block
 
-star_expressions[expr_ty]:
+star_expressions[expr]:
     | a=star_expression b=(',' c=star_expression { c })+ [','] {
-        _Py_Tuple(CHECK(_PyPegen_seq_insert_in_front(p, a, b)), Load, EXTRA) }
-    | a=star_expression ',' { _Py_Tuple(CHECK(_PyPegen_singleton_seq(p, a)), Load, EXTRA) }
+        new astnodes.Tuple(CHECK(pegen.seq_insert_in_front(this, a, b)), new astnodes.Load(), ...EXTRA) }
+    | a=star_expression ',' { new astnodes.Tuple(CHECK(pegen.singleton_seq(this, a)), new astnodes.Load(), ...EXTRA) }
     | star_expression
-star_expression[expr_ty] (memo):
-    | '*' a=bitwise_or { _Py_Starred(a, Load, EXTRA) }
+star_expression[expr] (memo):
+    | '*' a=bitwise_or { new astnodes.Starred(a, new astnodes.Load(), ...EXTRA) }
     | expression
 
 star_named_expressions[asdl_seq*]: a=','.star_named_expression+ [','] { a }
-star_named_expression[expr_ty]:
-    | '*' a=bitwise_or { _Py_Starred(a, Load, EXTRA) }
+star_named_expression[expr]:
+    | '*' a=bitwise_or { new astnodes.Starred(a, new astnodes.Load(), ...EXTRA) }
     | named_expression
-named_expression[expr_ty]:
-    | a=NAME ':=' ~ b=expression { _Py_NamedExpr(CHECK(_PyPegen_set_expr_context(p, a, Store)), b, EXTRA) }
+named_expression[expr]:
+    | a=NAME ':=' ~ b=expression { new astnodes.NamedExpr(CHECK(pegen.set_expr_context(this, a, new astnodes.Store())), b, ...EXTRA) }
     | expression !':='
     | invalid_named_expression
 
-annotated_rhs[expr_ty]: yield_expr | star_expressions
+annotated_rhs[expr]: yield_expr | star_expressions
 
-expressions[expr_ty]:
+expressions[expr]:
     | a=expression b=(',' c=expression { c })+ [','] {
-        _Py_Tuple(CHECK(_PyPegen_seq_insert_in_front(p, a, b)), Load, EXTRA) }
-    | a=expression ',' { _Py_Tuple(CHECK(_PyPegen_singleton_seq(p, a)), Load, EXTRA) }
+        new astnodes.Tuple(CHECK(pegen.seq_insert_in_front(this, a, b)), new astnodes.Load(), ...EXTRA) }
+    | a=expression ',' { new astnodes.Tuple(CHECK(pegen.singleton_seq(this, a)), new astnodes.Load(), ...EXTRA) }
     | expression
-expression[expr_ty] (memo):
-    | a=disjunction 'if' b=disjunction 'else' c=expression { _Py_IfExp(b, a, c, EXTRA) }
+expression[expr] (memo):
+    | a=disjunction 'if' b=disjunction 'else' c=expression { new astnodes.IfExp(b, a, c, ...EXTRA) }
     | disjunction
     | lambdef
 
-lambdef[expr_ty]:
-    | 'lambda' a=[lambda_params] ':' b=expression { _Py_Lambda((a) ? a : CHECK(_PyPegen_empty_arguments(p)), b, EXTRA) }
+lambdef[expr]:
+    | 'lambda' a=[lambda_params] ':' b=expression { new astnodes.Lambda((a) ? a : CHECK(pegen.empty_arguments(p)), b, ...EXTRA) }
 
-lambda_params[arguments_ty]:
+lambda_params[arguments_]:
     | invalid_lambda_parameters
     | lambda_parameters
 
@@ -342,62 +340,62 @@ lambda_params[arguments_ty]:
 # or type comments, and if there's no comma after a parameter, we expect
 # a colon, not a close parenthesis.  (For more, see parameters above.)
 #
-lambda_parameters[arguments_ty]:
+lambda_parameters[arguments_]:
     | a=lambda_slash_no_default b=lambda_param_no_default* c=lambda_param_with_default* d=[lambda_star_etc] {
-        _PyPegen_make_arguments(p, a, NULL, b, c, d) }
+        pegen.make_arguments(this, a, null, b, c, d) }
     | a=lambda_slash_with_default b=lambda_param_with_default* c=[lambda_star_etc] {
-        _PyPegen_make_arguments(p, NULL, a, NULL, b, c) }
+        pegen.make_arguments(this, null, a, null, b, c) }
     | a=lambda_param_no_default+ b=lambda_param_with_default* c=[lambda_star_etc] {
-        _PyPegen_make_arguments(p, NULL, NULL, a, b, c) }
-    | a=lambda_param_with_default+ b=[lambda_star_etc] { _PyPegen_make_arguments(p, NULL, NULL, NULL, a, b)}
-    | a=lambda_star_etc { _PyPegen_make_arguments(p, NULL, NULL, NULL, NULL, a) }
+        pegen.make_arguments(this, null, null, a, b, c) }
+    | a=lambda_param_with_default+ b=[lambda_star_etc] { pegen.make_arguments(this, null, null, null, a, b)}
+    | a=lambda_star_etc { pegen.make_arguments(this, null, null, null, null, a) }
 
 lambda_slash_no_default[asdl_seq*]:
     | a=lambda_param_no_default+ '/' ',' { a }
     | a=lambda_param_no_default+ '/' &':' { a }
 lambda_slash_with_default[SlashWithDefault*]:
-    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' ',' { _PyPegen_slash_with_default(p, a, b) }
-    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' &':' { _PyPegen_slash_with_default(p, a, b) }
+    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' ',' { pegen.slash_with_default(this, a, b) }
+    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' &':' { pegen.slash_with_default(this, a, b) }
 
 lambda_star_etc[StarEtc*]:
     | '*' a=lambda_param_no_default b=lambda_param_maybe_default* c=[lambda_kwds] {
-        _PyPegen_star_etc(p, a, b, c) }
+        pegen.star_etc(this, a, b, c) }
     | '*' ',' b=lambda_param_maybe_default+ c=[lambda_kwds] {
-        _PyPegen_star_etc(p, NULL, b, c) }
-    | a=lambda_kwds { _PyPegen_star_etc(p, NULL, NULL, a) }
+        pegen.star_etc(this, null, b, c) }
+    | a=lambda_kwds { pegen.star_etc(this, null, null, a) }
     | invalid_lambda_star_etc
 
-lambda_kwds[arg_ty]: '**' a=lambda_param_no_default { a }
+lambda_kwds[arg]: '**' a=lambda_param_no_default { a }
 
-lambda_param_no_default[arg_ty]:
+lambda_param_no_default[arg]:
     | a=lambda_param ',' { a }
     | a=lambda_param &':' { a }
 lambda_param_with_default[NameDefaultPair*]:
-    | a=lambda_param c=default ',' { _PyPegen_name_default_pair(p, a, c, NULL) }
-    | a=lambda_param c=default &':' { _PyPegen_name_default_pair(p, a, c, NULL) }
+    | a=lambda_param c=default ',' { pegen.name_default_pair(this, a, c, null) }
+    | a=lambda_param c=default &':' { pegen.name_default_pair(this, a, c, null) }
 lambda_param_maybe_default[NameDefaultPair*]:
-    | a=lambda_param c=default? ',' { _PyPegen_name_default_pair(p, a, c, NULL) }
-    | a=lambda_param c=default? &':' { _PyPegen_name_default_pair(p, a, c, NULL) }
-lambda_param[arg_ty]: a=NAME { _Py_arg(a->v.Name.id, NULL, NULL, EXTRA) }
+    | a=lambda_param c=default? ',' { pegen.name_default_pair(this, a, c, null) }
+    | a=lambda_param c=default? &':' { pegen.name_default_pair(this, a, c, null) }
+lambda_param[arg]: a=NAME { new astnodes.arg(a.id, null, null, ...EXTRA) }
 
-disjunction[expr_ty] (memo):
-    | a=conjunction b=('or' c=conjunction { c })+ { _Py_BoolOp(
+disjunction[expr] (memo):
+    | a=conjunction b=('or' c=conjunction { c })+ { new astnodes.BoolOp(
         Or,
-        CHECK(_PyPegen_seq_insert_in_front(p, a, b)),
+        CHECK(pegen.seq_insert_in_front(this, a, b)),
         EXTRA) }
     | conjunction
-conjunction[expr_ty] (memo):
-    | a=inversion b=('and' c=inversion { c })+ { _Py_BoolOp(
+conjunction[expr] (memo):
+    | a=inversion b=('and' c=inversion { c })+ { new astnodes.BoolOp(
         And,
-        CHECK(_PyPegen_seq_insert_in_front(p, a, b)),
+        CHECK(pegen.seq_insert_in_front(this, a, b)),
         EXTRA) }
     | inversion
-inversion[expr_ty] (memo):
-    | 'not' a=inversion { _Py_UnaryOp(Not, a, EXTRA) }
+inversion[expr] (memo):
+    | 'not' a=inversion { new astnodes.UnaryOp(Not, a, ...EXTRA) }
     | comparison
-comparison[expr_ty]:
+comparison[expr]:
     | a=bitwise_or b=compare_op_bitwise_or_pair+ {
-        _Py_Compare(a, CHECK(_PyPegen_get_cmpops(p, b)), CHECK(_PyPegen_get_exprs(p, b)), EXTRA) }
+        new astnodes.Compare(a, CHECK(pegen.get_cmpops(this, b)), CHECK(pegen.get_exprs(this, b)), ...EXTRA) }
     | bitwise_or
 compare_op_bitwise_or_pair[CmpopExprPair*]:
     | eq_bitwise_or
@@ -410,217 +408,217 @@ compare_op_bitwise_or_pair[CmpopExprPair*]:
     | in_bitwise_or
     | isnot_bitwise_or
     | is_bitwise_or
-eq_bitwise_or[CmpopExprPair*]: '==' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Eq, a) }
+eq_bitwise_or[CmpopExprPair*]: '==' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.Eq(), a) }
 noteq_bitwise_or[CmpopExprPair*]:
-    | (tok='!=' { _PyPegen_check_barry_as_flufl(p, tok) ? NULL : tok}) a=bitwise_or {_PyPegen_cmpop_expr_pair(p, NotEq, a) }
-lte_bitwise_or[CmpopExprPair*]: '<=' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, LtE, a) }
-lt_bitwise_or[CmpopExprPair*]: '<' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Lt, a) }
-gte_bitwise_or[CmpopExprPair*]: '>=' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, GtE, a) }
-gt_bitwise_or[CmpopExprPair*]: '>' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Gt, a) }
-notin_bitwise_or[CmpopExprPair*]: 'not' 'in' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, NotIn, a) }
-in_bitwise_or[CmpopExprPair*]: 'in' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, In, a) }
-isnot_bitwise_or[CmpopExprPair*]: 'is' 'not' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, IsNot, a) }
-is_bitwise_or[CmpopExprPair*]: 'is' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Is, a) }
-
-bitwise_or[expr_ty]:
-    | a=bitwise_or '|' b=bitwise_xor { _Py_BinOp(a, BitOr, b, EXTRA) }
+    | (tok='!=' { pegen.check_barry_as_flufl(this, tok) ? null : tok}) a=bitwise_or {pegen.cmpop_expr_pair(this, new astnodes.NotEq(), a) }
+lte_bitwise_or[CmpopExprPair*]: '<=' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.LtE(), a) }
+lt_bitwise_or[CmpopExprPair*]: '<' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.Lt(), a) }
+gte_bitwise_or[CmpopExprPair*]: '>=' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.GtE(), a) }
+gt_bitwise_or[CmpopExprPair*]: '>' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.Gt(), a) }
+notin_bitwise_or[CmpopExprPair*]: 'not' 'in' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.NotIn(), a) }
+in_bitwise_or[CmpopExprPair*]: 'in' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.In(), a) }
+isnot_bitwise_or[CmpopExprPair*]: 'is' 'not' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.IsNot(), a) }
+is_bitwise_or[CmpopExprPair*]: 'is' a=bitwise_or { pegen.cmpop_expr_pair(this, new astnodes.Is(), a) }
+
+bitwise_or[expr]:
+    | a=bitwise_or '|' b=bitwise_xor { new astnodes.BinOp(a, new astnodes.BitOr(), b, ...EXTRA) }
     | bitwise_xor
-bitwise_xor[expr_ty]:
-    | a=bitwise_xor '^' b=bitwise_and { _Py_BinOp(a, BitXor, b, EXTRA) }
+bitwise_xor[expr]:
+    | a=bitwise_xor '^' b=bitwise_and { new astnodes.BinOp(a, new astnodes.BitXor(), b, ...EXTRA) }
     | bitwise_and
-bitwise_and[expr_ty]:
-    | a=bitwise_and '&' b=shift_expr { _Py_BinOp(a, BitAnd, b, EXTRA) }
+bitwise_and[expr]:
+    | a=bitwise_and '&' b=shift_expr { new astnodes.BinOp(a, new astnodes.BitAnd(), b, ...EXTRA) }
     | shift_expr
-shift_expr[expr_ty]:
-    | a=shift_expr '<<' b=sum { _Py_BinOp(a, LShift, b, EXTRA) }
-    | a=shift_expr '>>' b=sum { _Py_BinOp(a, RShift, b, EXTRA) }
+shift_expr[expr]:
+    | a=shift_expr '<<' b=sum { new astnodes.BinOp(a, new astnodes.LShift(), b, ...EXTRA) }
+    | a=shift_expr '>>' b=sum { new astnodes.BinOp(a, new astnodes.RShift(), b, ...EXTRA) }
     | sum
 
-sum[expr_ty]:
-    | a=sum '+' b=term { _Py_BinOp(a, Add, b, EXTRA) }
-    | a=sum '-' b=term { _Py_BinOp(a, Sub, b, EXTRA) }
+sum[expr]:
+    | a=sum '+' b=term { new astnodes.BinOp(a, new astnodes.Add(), b, ...EXTRA) }
+    | a=sum '-' b=term { new astnodes.BinOp(a, new astnodes.Sub(), b, ...EXTRA) }
     | term
-term[expr_ty]:
-    | a=term '*' b=factor { _Py_BinOp(a, Mult, b, EXTRA) }
-    | a=term '/' b=factor { _Py_BinOp(a, Div, b, EXTRA) }
-    | a=term '//' b=factor { _Py_BinOp(a, FloorDiv, b, EXTRA) }
-    | a=term '%' b=factor { _Py_BinOp(a, Mod, b, EXTRA) }
-    | a=term '@' b=factor { CHECK_VERSION(5, "The '@' operator is", _Py_BinOp(a, MatMult, b, EXTRA)) }
+term[expr]:
+    | a=term '*' b=factor { new astnodes.BinOp(a, new astnodes.Mult(), b, ...EXTRA) }
+    | a=term '/' b=factor { new astnodes.BinOp(a, new astnodes.Div(), b, ...EXTRA) }
+    | a=term '//' b=factor { new astnodes.BinOp(a, new astnodes.FloorDiv(), b, ...EXTRA) }
+    | a=term '%' b=factor { new astnodes.BinOp(a, new astnodes.Mod(), b, ...EXTRA) }
+    | a=term '@' b=factor { CHECK_VERSION(5, "The '@' operator is", new astnodes.BinOp(a, MatMult, b, ...EXTRA)) }
     | factor
-factor[expr_ty] (memo):
-    | '+' a=factor { _Py_UnaryOp(UAdd, a, EXTRA) }
-    | '-' a=factor { _Py_UnaryOp(USub, a, EXTRA) }
-    | '~' a=factor { _Py_UnaryOp(Invert, a, EXTRA) }
+factor[expr] (memo):
+    | '+' a=factor { new astnodes.UnaryOp(new astnodes.UAdd(), a, ...EXTRA) }
+    | '-' a=factor { new astnodes.UnaryOp(new astnodes.USub(), a, ...EXTRA) }
+    | '~' a=factor { new astnodes.UnaryOp(new astnodes.Invert(), a, ...EXTRA) }
     | power
-power[expr_ty]:
-    | a=await_primary '**' b=factor { _Py_BinOp(a, Pow, b, EXTRA) }
+power[expr]:
+    | a=await_primary '**' b=factor { new astnodes.BinOp(a, Pow, b, ...EXTRA) }
     | await_primary
-await_primary[expr_ty] (memo):
-    | AWAIT a=primary { CHECK_VERSION(5, "Await expressions are", _Py_Await(a, EXTRA)) }
+await_primary[expr] (memo):
+    | AWAIT a=primary { CHECK_VERSION(5, "Await expressions are", new astnodes.Await(a, ...EXTRA)) }
     | primary
-primary[expr_ty]:
+primary[expr]:
     | invalid_primary  # must be before 'primay genexp' because of invalid_genexp
-    | a=primary '.' b=NAME { _Py_Attribute(a, b->v.Name.id, Load, EXTRA) }
-    | a=primary b=genexp { _Py_Call(a, CHECK(_PyPegen_singleton_seq(p, b)), NULL, EXTRA) }
-    | a=primary '(' b=[arguments] ')' {
-        _Py_Call(a,
-                 (b) ? ((expr_ty) b)->v.Call.args : NULL,
-                 (b) ? ((expr_ty) b)->v.Call.keywords : NULL,
+    | a=primary '.' b=NAME { new astnodes.Attribute(a, b.id, new astnodes.Load(), ...EXTRA) }
+    | a=primary b=genexp { new astnodes.Call(a, CHECK(pegen.singleton_seq(this, b)), null, ...EXTRA) }
+    | a=primary '(' b=[arguments_] ')' {
+        new astnodes.Call(a,
+                 b ? b.args : null,
+                 b ? b.keywords : null,
                  EXTRA) }
-    | a=primary '[' b=slices ']' { _Py_Subscript(a, b, Load, EXTRA) }
+    | a=primary '[' b=slices ']' { new astnodes.Subscript(a, b, new astnodes.Load(), ...EXTRA) }
     | atom
 
-slices[expr_ty]:
+slices[expr]:
     | a=slice !',' { a }
-    | a=','.slice+ [','] { _Py_Tuple(a, Load, EXTRA) }
-slice[expr_ty]:
-    | a=[expression] ':' b=[expression] c=[':' d=[expression] { d }] { _Py_Slice(a, b, c, EXTRA) }
+    | a=','.slice+ [','] { new astnodes.Tuple(a, new astnodes.Load(), ...EXTRA) }
+slice[expr]:
+    | a=[expression] ':' b=[expression] c=[':' d=[expression] { d }] { new astnodes.Slice(a, b, c, ...EXTRA) }
     | a=expression { a }
-atom[expr_ty]:
+atom[expr]:
     | NAME
-    | 'True' { _Py_Constant(Py_True, NULL, EXTRA) }
-    | 'False' { _Py_Constant(Py_False, NULL, EXTRA) }
-    | 'None' { _Py_Constant(Py_None, NULL, EXTRA) }
+    | 'True' { new astnodes.Constant(Py_True, null, ...EXTRA) }
+    | 'False' { new astnodes.Constant(Py_False, null, ...EXTRA) }
+    | 'None' { new astnodes.Constant(Py_None, null, ...EXTRA) }
     | '__peg_parser__' { RAISE_SYNTAX_ERROR("You found it!") }
     | &STRING strings
     | NUMBER
     | &'(' (tuple | group | genexp)
     | &'[' (list | listcomp)
     | &'{' (dict | set | dictcomp | setcomp)
-    | '...' { _Py_Constant(Py_Ellipsis, NULL, EXTRA) }
+    | '...' { new astnodes.Constant(Py_Ellipsis, null, ...EXTRA) }
 
-strings[expr_ty] (memo): a=STRING+ { _PyPegen_concatenate_strings(p, a) }
-list[expr_ty]:
-    | '[' a=[star_named_expressions] ']' { _Py_List(a, Load, EXTRA) }
-listcomp[expr_ty]:
-    | '[' a=named_expression ~ b=for_if_clauses ']' { _Py_ListComp(a, b, EXTRA) }
+strings[expr] (memo): a=STRING+ { pegen.concatenate_strings(this, a) }
+list[expr]:
+    | '[' a=[star_named_expressions] ']' { new astnodes.List(a, new astnodes.Load(), ...EXTRA) }
+listcomp[expr]:
+    | '[' a=named_expression ~ b=for_if_clauses ']' { new astnodes.ListComp(a, b, ...EXTRA) }
     | invalid_comprehension
-tuple[expr_ty]:
-    | '(' a=[y=star_named_expression ',' z=[star_named_expressions] { _PyPegen_seq_insert_in_front(p, y, z) } ] ')' {
-        _Py_Tuple(a, Load, EXTRA) }
-group[expr_ty]:
+tuple[expr]:
+    | '(' a=[y=star_named_expression ',' z=[star_named_expressions] { pegen.seq_insert_in_front(this, y, z) } ] ')' {
+        new astnodes.Tuple(a, new astnodes.Load(), ...EXTRA) }
+group[expr]:
     | '(' a=(yield_expr | named_expression) ')' { a }
     | invalid_group
-genexp[expr_ty]:
-    | '(' a=named_expression ~ b=for_if_clauses ')' { _Py_GeneratorExp(a, b, EXTRA) }
+genexp[expr]:
+    | '(' a=named_expression ~ b=for_if_clauses ')' { new astnodes.GeneratorExp(a, b, ...EXTRA) }
     | invalid_comprehension
-set[expr_ty]: '{' a=star_named_expressions '}' { _Py_Set(a, EXTRA) }
-setcomp[expr_ty]:
-    | '{' a=named_expression ~ b=for_if_clauses '}' { _Py_SetComp(a, b, EXTRA) }
+set[expr]: '{' a=star_named_expressions '}' { new astnodes.Set(a, ...EXTRA) }
+setcomp[expr]:
+    | '{' a=named_expression ~ b=for_if_clauses '}' { new astnodes.SetComp(a, b, ...EXTRA) }
     | invalid_comprehension
-dict[expr_ty]:
+dict[expr]:
     | '{' a=[double_starred_kvpairs] '}' {
-        _Py_Dict(CHECK(_PyPegen_get_keys(p, a)), CHECK(_PyPegen_get_values(p, a)), EXTRA) }
-dictcomp[expr_ty]:
-    | '{' a=kvpair b=for_if_clauses '}' { _Py_DictComp(a->key, a->value, b, EXTRA) }
+        new astnodes.Dict(CHECK(pegen.get_keys(this, a)), CHECK(pegen.get_values(this, a)), ...EXTRA) }
+dictcomp[expr]:
+    | '{' a=kvpair b=for_if_clauses '}' { new astnodes.DictComp(a.key, a.value, b, ...EXTRA) }
     | invalid_dict_comprehension
 double_starred_kvpairs[asdl_seq*]: a=','.double_starred_kvpair+ [','] { a }
 double_starred_kvpair[KeyValuePair*]:
-    | '**' a=bitwise_or { _PyPegen_key_value_pair(p, NULL, a) }
+    | '**' a=bitwise_or { pegen.key_value_pair(this, null, a) }
     | kvpair
-kvpair[KeyValuePair*]: a=expression ':' b=expression { _PyPegen_key_value_pair(p, a, b) }
+kvpair[KeyValuePair*]: a=expression ':' b=expression { pegen.key_value_pair(this, a, b) }
 for_if_clauses[asdl_seq*]:
     | for_if_clause+
-for_if_clause[comprehension_ty]:
+for_if_clause[comprehension]:
     | ASYNC 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction { z })* {
-        CHECK_VERSION(6, "Async comprehensions are", _Py_comprehension(a, b, c, 1, p->arena)) }
+        CHECK_VERSION(6, "Async comprehensions are", new astnodes.comprehension(a, b, c, 1)) }
     | 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction { z })* {
-        _Py_comprehension(a, b, c, 0, p->arena) }
+        new astnodes.comprehension(a, b, c, 0) }
     | invalid_for_target
 
-yield_expr[expr_ty]:
-    | 'yield' 'from' a=expression { _Py_YieldFrom(a, EXTRA) }
-    | 'yield' a=[star_expressions] { _Py_Yield(a, EXTRA) }
+yield_expr[expr]:
+    | 'yield' 'from' a=expression { new astnodes.YieldFrom(a, ...EXTRA) }
+    | 'yield' a=[star_expressions] { new astnodes.Yield(a, ...EXTRA) }
 
-arguments[expr_ty] (memo):
+arguments_[expr] (memo):
     | a=args [','] &')' { a }
     | invalid_arguments
-args[expr_ty]:
-    | a=','.(starred_expression | named_expression !'=')+ b=[',' k=kwargs {k}] { _PyPegen_collect_call_seqs(p, a, b, EXTRA) }
-    | a=kwargs { _Py_Call(_PyPegen_dummy_name(p),
-                          CHECK_NULL_ALLOWED(_PyPegen_seq_extract_starred_exprs(p, a)),
-                          CHECK_NULL_ALLOWED(_PyPegen_seq_delete_starred_exprs(p, a)),
+args[expr]:
+    | a=','.(starred_expression | named_expression !'=')+ b=[',' k=kwargs {k}] { pegen.collect_call_seqs(this, a, b, ...EXTRA) }
+    | a=kwargs { new astnodes.Call(pegen.dummy_name(p),
+                          CHECK_NULL_ALLOWED(pegen.seq_extract_starred_exprs(this, a)),
+                          CHECK_NULL_ALLOWED(pegen.seq_delete_starred_exprs(this, a)),
                           EXTRA) }
 kwargs[asdl_seq*]:
-    | a=','.kwarg_or_starred+ ',' b=','.kwarg_or_double_starred+ { _PyPegen_join_sequences(p, a, b) }
+    | a=','.kwarg_or_starred+ ',' b=','.kwarg_or_double_starred+ { pegen.join_sequences(this, a, b) }
     | ','.kwarg_or_starred+
     | ','.kwarg_or_double_starred+
-starred_expression[expr_ty]:
-    | '*' a=expression { _Py_Starred(a, Load, EXTRA) }
+starred_expression[expr]:
+    | '*' a=expression { new astnodes.Starred(a, new astnodes.Load(), ...EXTRA) }
 kwarg_or_starred[KeywordOrStarred*]:
     | a=NAME '=' b=expression {
-        _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(a->v.Name.id, b, EXTRA)), 1) }
-    | a=starred_expression { _PyPegen_keyword_or_starred(p, a, 0) }
+        pegen.keyword_or_starred(this, CHECK(new astnodes.keyword(a.id, b, ...EXTRA)), true) }
+    | a=starred_expression { pegen.keyword_or_starred(this, a, false) }
     | invalid_kwarg
 kwarg_or_double_starred[KeywordOrStarred*]:
     | a=NAME '=' b=expression {
-        _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(a->v.Name.id, b, EXTRA)), 1) }
-    | '**' a=expression { _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(NULL, a, EXTRA)), 1) }
+        fkeyword_or_starred(this, CHECK(new astnodes.keyword(a.id, b, ...EXTRA)), 1) }
+    | '**' a=expression { pegen.keyword_or_starred(this, CHECK(new astnodes.keyword(null, a, ...EXTRA)), 1) }
     | invalid_kwarg
 
 # NOTE: star_targets may contain *bitwise_or, targets may not.
-star_targets[expr_ty]:
+star_targets[expr]:
     | a=star_target !',' { a }
     | a=star_target b=(',' c=star_target { c })* [','] {
-        _Py_Tuple(CHECK(_PyPegen_seq_insert_in_front(p, a, b)), Store, EXTRA) }
+        new astnodes.Tuple(CHECK(pegen.seq_insert_in_front(this, a, b)), new astnodes.Store(), ...EXTRA) }
 star_targets_list_seq[asdl_seq*]: a=','.star_target+ [','] { a }
 star_targets_tuple_seq[asdl_seq*]:
-    | a=star_target b=(',' c=star_target { c })+ [','] { _PyPegen_seq_insert_in_front(p, a, b) }
-    | a=star_target ',' { _PyPegen_singleton_seq(p, a) }
-star_target[expr_ty] (memo):
+    | a=star_target b=(',' c=star_target { c })+ [','] { pegen.seq_insert_in_front(this, a, b) }
+    | a=star_target ',' { pegen.singleton_seq(this, a) }
+star_target[expr] (memo):
     | '*' a=(!'*' star_target) {
-        _Py_Starred(CHECK(_PyPegen_set_expr_context(p, a, Store)), Store, EXTRA) }
+        new astnodes.Starred(CHECK(pegen.set_expr_context(this, a, new astnodes.Store())), new astnodes.Store(), ...EXTRA) }
     | target_with_star_atom
-target_with_star_atom[expr_ty] (memo):
-    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, Store, EXTRA) }
-    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Store, EXTRA) }
+target_with_star_atom[expr] (memo):
+    | a=t_primary '.' b=NAME !t_lookahead { new astnodes.Attribute(a, b.id, new astnodes.Store(), ...EXTRA) }
+    | a=t_primary '[' b=slices ']' !t_lookahead { new astnodes.Subscript(a, b, new astnodes.Store(), ...EXTRA) }
     | star_atom
-star_atom[expr_ty]:
-    | a=NAME { _PyPegen_set_expr_context(p, a, Store) }
-    | '(' a=target_with_star_atom ')' { _PyPegen_set_expr_context(p, a, Store) }
-    | '(' a=[star_targets_tuple_seq] ')' { _Py_Tuple(a, Store, EXTRA) }
-    | '[' a=[star_targets_list_seq] ']' { _Py_List(a, Store, EXTRA) }
+star_atom[expr]:
+    | a=NAME { pegen.set_expr_context(this, a, new astnodes.Store()) }
+    | '(' a=target_with_star_atom ')' { pegen.set_expr_context(this, a, new astnodes.Store()) }
+    | '(' a=[star_targets_tuple_seq] ')' { new astnodes.Tuple(a, new astnodes.Store(), ...EXTRA) }
+    | '[' a=[star_targets_list_seq] ']' { new astnodes.List(a, new astnodes.Store(), ...EXTRA) }
 
-single_target[expr_ty]:
+single_target[expr]:
     | single_subscript_attribute_target
-    | a=NAME { _PyPegen_set_expr_context(p, a, Store) }
+    | a=NAME { pegen.set_expr_context(this, a, new astnodes.Store()) }
     | '(' a=single_target ')' { a }
-single_subscript_attribute_target[expr_ty]:
-    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, Store, EXTRA) }
-    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Store, EXTRA) }
+single_subscript_attribute_target[expr]:
+    | a=t_primary '.' b=NAME !t_lookahead { new astnodes.Attribute(a, b.id, new astnodes.Store(), ...EXTRA) }
+    | a=t_primary '[' b=slices ']' !t_lookahead { new astnodes.Subscript(a, b, new astnodes.Store(), ...EXTRA) }
 
 del_targets[asdl_seq*]: a=','.del_target+ [','] { a }
-del_target[expr_ty] (memo):
-    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, Del, EXTRA) }
-    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Del, EXTRA) }
+del_target[expr] (memo):
+    | a=t_primary '.' b=NAME !t_lookahead { new astnodes.Attribute(a, b.id, Del, ...EXTRA) }
+    | a=t_primary '[' b=slices ']' !t_lookahead { new astnodes.Subscript(a, b, Del, ...EXTRA) }
     | del_t_atom
-del_t_atom[expr_ty]:
-    | a=NAME { _PyPegen_set_expr_context(p, a, Del) }
-    | '(' a=del_target ')' { _PyPegen_set_expr_context(p, a, Del) }
-    | '(' a=[del_targets] ')' { _Py_Tuple(a, Del, EXTRA) }
-    | '[' a=[del_targets] ']' { _Py_List(a, Del, EXTRA) }
+del_t_atom[expr]:
+    | a=NAME { pegen.set_expr_context(this, a, Del) }
+    | '(' a=del_target ')' { pegen.set_expr_context(this, a, Del) }
+    | '(' a=[del_targets] ')' { new astnodes.Tuple(a, Del, ...EXTRA) }
+    | '[' a=[del_targets] ']' { new astnodes.List(a, Del, ...EXTRA) }
 
 targets[asdl_seq*]: a=','.target+ [','] { a }
-target[expr_ty] (memo):
-    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, Store, EXTRA) }
-    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Store, EXTRA) }
+target[expr] (memo):
+    | a=t_primary '.' b=NAME !t_lookahead { new astnodes.Attribute(a, b.id, new astnodes.Store(), ...EXTRA) }
+    | a=t_primary '[' b=slices ']' !t_lookahead { new astnodes.Subscript(a, b, new astnodes.Store(), ...EXTRA) }
     | t_atom
-t_primary[expr_ty]:
-    | a=t_primary '.' b=NAME &t_lookahead { _Py_Attribute(a, b->v.Name.id, Load, EXTRA) }
-    | a=t_primary '[' b=slices ']' &t_lookahead { _Py_Subscript(a, b, Load, EXTRA) }
-    | a=t_primary b=genexp &t_lookahead { _Py_Call(a, CHECK(_PyPegen_singleton_seq(p, b)), NULL, EXTRA) }
-    | a=t_primary '(' b=[arguments] ')' &t_lookahead {
-        _Py_Call(a,
-                 (b) ? ((expr_ty) b)->v.Call.args : NULL,
-                 (b) ? ((expr_ty) b)->v.Call.keywords : NULL,
+t_primary[expr]:
+    | a=t_primary '.' b=NAME &t_lookahead { new astnodes.Attribute(a, b.id, new astnodes.Load(), ...EXTRA) }
+    | a=t_primary '[' b=slices ']' &t_lookahead { new astnodes.Subscript(a, b, new astnodes.Load(), ...EXTRA) }
+    | a=t_primary b=genexp &t_lookahead { new astnodes.Call(a, CHECK(pegen.singleton_seq(this, b)), null, ...EXTRA) }
+    | a=t_primary '(' b=[arguments_] ')' &t_lookahead {
+        new astnodes.Call(a,
+                 b ? b.args : null,
+                 b ? b.keywords : null,
                  EXTRA) }
     | a=atom &t_lookahead { a }
 t_lookahead: '(' | '[' | '.'
 t_atom[expr_ty]:
-    | a=NAME { _PyPegen_set_expr_context(p, a, Store) }
-    | '(' a=target ')' { _PyPegen_set_expr_context(p, a, Store) }
-    | '(' b=[targets] ')' { _Py_Tuple(b, Store, EXTRA) }
-    | '[' b=[targets] ']' { _Py_List(b, Store, EXTRA) }
+    | a=NAME { pegen.set_expr_context(this, a, new astnodes.Store()) }
+    | '(' a=target ')' { pegen.set_expr_context(this, a, new astnodes.Store()) }
+    | '(' b=[targets] ')' { new astnodes.Tuple(b, new astnodes.Store(), ...EXTRA) }
+    | '[' b=[targets] ']' { new astnodes.List(b, new astnodes.Store(), ...EXTRA) }
 
 
 # From here on, there are rules for invalid syntax with specialised error messages
@@ -628,10 +626,10 @@ invalid_arguments:
     | args ',' '*' { RAISE_SYNTAX_ERROR("iterable argument unpacking follows keyword argument unpacking") }
     | a=expression for_if_clauses ',' [args | expression for_if_clauses] {
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "Generator expression must be parenthesized") }
-    | a=args for_if_clauses { _PyPegen_nonparen_genexp_in_call(p, a) }
+    | a=args for_if_clauses { pegen.nonparen_genexp_in_call(this, a) }
     | args ',' a=expression for_if_clauses {
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "Generator expression must be parenthesized") }
-    | a=args ',' args { _PyPegen_arguments_parsing_error(p, a) }
+    | a=args ',' args { pegen.arguments_parsing_error(this, a) }
 invalid_kwarg:
     | a=expression '=' {
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
@@ -639,13 +637,13 @@ invalid_kwarg:
 invalid_named_expression:
     | a=expression ':=' expression {
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
-            a, "cannot use assignment expressions with %s", _PyPegen_get_expr_name(a)) }
+            a, "cannot use assignment expressions with %s", pegen.get_expr_name(a)) }
 invalid_assignment:
     | a=invalid_ann_assign_target ':' expression {
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
             a,
             "only single target (not %s) can be annotated",
-            _PyPegen_get_expr_name(a)
+            pegen.get_expr_name(a)
         )}
     | a=star_named_expression ',' star_named_expressions* ':' expression {
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "only single target (not tuple) can be annotated") }
@@ -658,7 +656,7 @@ invalid_assignment:
         RAISE_SYNTAX_ERROR_KNOWN_LOCATION( 
             a,
             "'%s' is an illegal expression for augmented assignment",
-            _PyPegen_get_expr_name(a)
+            pegen.get_expr_name(a)
         )}
 invalid_ann_assign_target[expr_ty]:
     | list
